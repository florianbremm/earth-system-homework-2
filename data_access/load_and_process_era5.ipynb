{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T18:37:10.210142Z",
     "start_time": "2026-01-18T18:37:09.870646Z"
    }
   },
   "source": [
    "import cdsapi\n",
    "import healpy as hp\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "#additional packages"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T18:37:10.216356Z",
     "start_time": "2026-01-18T18:37:10.214248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CONFIG\n",
    "\n",
    "#====== download config ======#\n",
    "\n",
    "variables=['specific_humidity'] # other variables can be found at https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#ERA5:datadocumentation-Table9. This notebook was only developed for continues pressure level variables\n",
    "\n",
    "pressure_levels = ['300', '500', '800', '900', '975']\n",
    "\n",
    "temporal_extend = {\n",
    "    \"start\": '2024-12-01',\n",
    "    \"end\": '2024-12-05',\n",
    "    \"times\": ['00:00:00', '06:00:00', '12:00:00', '18:00:00'],\n",
    "}\n",
    "\n",
    "spacial_extend = 'global' #for a limited area provide an array of shape [north, west, south, east]. north, south of range [-90, 90] west, east [-180, 180]\n",
    "\n",
    "data_format = 'netcdf' # Downstream Processing requires netcdf so only change this variable if you want to change the processing pipeline\n",
    "\n",
    "grid = ['0.25', '0.25'] # [res_long, res_lat] resolution of the grid for the download. The specified 0.25Â° are the default resolution for atmospheric data in the ERA5 Dataset\n",
    "\n",
    "#===== regridding config =====#\n",
    "\n",
    "nsides = [8, 16]\n",
    "interpolation_method = 'linear' # methode for the interpolation to healpix (one of \"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\", \"quintic\", \"polynomial\")"
   ],
   "id": "ea1bf57cb8e05ee8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T18:37:10.223889Z",
     "start_time": "2026-01-18T18:37:10.220879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This cell iterates over the time period defined in temporal_extend and creates a dict containing day month and year for each day in the interval. This will later be used for the main downloading loop\n",
    "start_date = datetime.strptime(temporal_extend[\"start\"], '%Y-%m-%d')\n",
    "end_date = datetime.strptime(temporal_extend[\"end\"], '%Y-%m-%d')\n",
    "\n",
    "time_chunks = []\n",
    "for delta in range((end_date - start_date).days + 1): # iterate over the date range to create a dict for each day in our time_chunks list. Later we can loop over those list entries to loop over the days\n",
    "    i_date = start_date + timedelta(days=delta)\n",
    "    time_chunks.append({\n",
    "        \"day\": i_date.day,\n",
    "        \"month\": i_date.month,\n",
    "        \"year\": i_date.year\n",
    "    })\n",
    "\n",
    "time_chunks[:3] # :3 needed to limit console size for bigger temporal extends"
   ],
   "id": "a8b46348c7b7f540",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'day': 1, 'month': 12, 'year': 2024},\n",
       " {'day': 2, 'month': 12, 'year': 2024},\n",
       " {'day': 3, 'month': 12, 'year': 2024}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T18:37:10.238792Z",
     "start_time": "2026-01-18T18:37:10.236196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract the calculations for the healpix grids out of the main routine, so we don't do them multiple times (potentially for a lot of days / nside resolutions, amounting to a lot of calculations)\n",
    "hp_grids = []\n",
    "\n",
    "for nside in nsides: # iterate over nside resolutions and create the grid so we don't have to do it multiple tim\n",
    "    n_pix = hp.nside2npix(nside) # calculate number of pixels\n",
    "    theta, phi = hp.pix2ang(nside, np.arange(n_pix)) # calculate the pixel centers for each pixel in rad\n",
    "\n",
    "    hp_latitude = 90 - np.degrees(theta) # convert to degrees (North Pole = 0, South Pole = 180) and subtract from 90 to get to (North Pole = 90, South Pole = -90)\n",
    "    hp_longitude = np.degrees(phi) # convert to degrees (Greenwich = 0, increasing eastwards)\n",
    "\n",
    "    hp_grids.append({\"latitude\": hp_latitude, \"longitude\": hp_longitude})"
   ],
   "id": "6b09c553da7ed0d5",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T18:44:34.698206Z",
     "start_time": "2026-01-18T18:44:01.731203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = cdsapi.Client()\n",
    "\n",
    "for time_chunk in time_chunks:\n",
    "    c.retrieve('reanalysis-era5-pressure-levels', {\n",
    "        \"product_type\": ['reanalysis'],\n",
    "        \"variable\": variables,\n",
    "        \"year\": time_chunk[\"year\"],\n",
    "        \"month\": time_chunk[\"month\"],\n",
    "        \"day\": time_chunk[\"day\"],\n",
    "        \"time\": temporal_extend[\"times\"],\n",
    "        \"pressure_level\": pressure_levels,\n",
    "        \"grid\": grid,\n",
    "        \"area\": spacial_extend,\n",
    "       \"data_format\": data_format,\n",
    "    }, 'temp.nc')\n",
    "\n",
    "    ds = xr.open_dataset('temp.nc')\n",
    "    ds = ds.sortby('latitude')\n",
    "\n",
    "    for hp_grid in hp_grids:\n",
    "        ds_hp = ds.interp(\n",
    "            latitude=xr.DataArray(hp_grid[\"latitude\"]),\n",
    "            longitude=xr.DataArray(hp_grid[\"longitude\"]),\n",
    "            method=interpolation_method\n",
    "        )\n",
    "\n",
    "        for var in ds.data_vars:\n",
    "            print(var, float(ds[var].mean()), float(ds_hp[var].mean()))"
   ],
   "id": "2eb425472bbda376",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 19:44:03,622 INFO Request ID is 0ae0cb85-facb-49a7-81d0-8fdaa5f8ada5\n",
      "2026-01-18 19:44:03,695 INFO status has been updated to accepted\n",
      "2026-01-18 19:44:17,497 INFO status has been updated to running\n",
      "2026-01-18 19:44:25,168 INFO status has been updated to successful\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q 0.0032974048517644405 0.004441537493698019\n",
      "q 0.0032974048517644405 0.004451620876887112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-18 19:44:28,750 INFO Request ID is 0442c890-80f7-4c43-985d-2b8fd96c2368\n",
      "2026-01-18 19:44:28,793 INFO status has been updated to accepted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m c = cdsapi.Client()\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m time_chunk \u001B[38;5;129;01min\u001B[39;00m time_chunks:\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     \u001B[43mc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mreanalysis-era5-pressure-levels\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mproduct_type\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mreanalysis\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvariable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43myear\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime_chunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43myear\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmonth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime_chunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmonth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mday\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime_chunk\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mday\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtime\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemporal_extend\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtimes\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpressure_level\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpressure_levels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgrid\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43marea\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mspacial_extend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m       \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtemp.nc\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     ds = xr.open_dataset(\u001B[33m'\u001B[39m\u001B[33mtemp.nc\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     18\u001B[39m     ds = ds.sortby(\u001B[33m'\u001B[39m\u001B[33mlatitude\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/earth-systems-homework-assignment-1-gqaom8D6/lib/python3.12/site-packages/ecmwf/datastores/legacy_client.py:167\u001B[39m, in \u001B[36mLegacyClient.retrieve\u001B[39m\u001B[34m(self, name, request, target)\u001B[39m\n\u001B[32m    165\u001B[39m submitted: datastores.Remote | datastores.Results\n\u001B[32m    166\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.wait_until_complete:\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     submitted = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43msubmit_and_wait_on_results\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    168\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollection_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    169\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    172\u001B[39m     submitted = \u001B[38;5;28mself\u001B[39m.client.submit(\n\u001B[32m    173\u001B[39m         collection_id=name,\n\u001B[32m    174\u001B[39m         request=request,\n\u001B[32m    175\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/earth-systems-homework-assignment-1-gqaom8D6/lib/python3.12/site-packages/ecmwf/datastores/client.py:414\u001B[39m, in \u001B[36mClient.submit_and_wait_on_results\u001B[39m\u001B[34m(self, collection_id, request)\u001B[39m\n\u001B[32m    398\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msubmit_and_wait_on_results\u001B[39m(\n\u001B[32m    399\u001B[39m     \u001B[38;5;28mself\u001B[39m, collection_id: \u001B[38;5;28mstr\u001B[39m, request: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]\n\u001B[32m    400\u001B[39m ) -> datastores.Results:\n\u001B[32m    401\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Submit a request and wait for the results to be ready.\u001B[39;00m\n\u001B[32m    402\u001B[39m \n\u001B[32m    403\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    412\u001B[39m \u001B[33;03m    datastores.Results\u001B[39;00m\n\u001B[32m    413\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m414\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_retrieve_api\u001B[49m\u001B[43m.\u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcollection_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/earth-systems-homework-assignment-1-gqaom8D6/lib/python3.12/site-packages/ecmwf/datastores/processing.py:495\u001B[39m, in \u001B[36mRemote.get_results\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    488\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_results\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Results:\n\u001B[32m    489\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Retrieve results.\u001B[39;00m\n\u001B[32m    490\u001B[39m \n\u001B[32m    491\u001B[39m \u001B[33;03m    Returns\u001B[39;00m\n\u001B[32m    492\u001B[39m \u001B[33;03m    -------\u001B[39;00m\n\u001B[32m    493\u001B[39m \u001B[33;03m    datastores.Results\u001B[39;00m\n\u001B[32m    494\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m495\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/earth-systems-homework-assignment-1-gqaom8D6/lib/python3.12/site-packages/ecmwf/datastores/processing.py:479\u001B[39m, in \u001B[36mRemote._make_results\u001B[39m\u001B[34m(self, wait)\u001B[39m\n\u001B[32m    477\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_make_results\u001B[39m(\u001B[38;5;28mself\u001B[39m, wait: \u001B[38;5;28mbool\u001B[39m) -> Results:\n\u001B[32m    478\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m wait:\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wait_on_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    480\u001B[39m     response = \u001B[38;5;28mself\u001B[39m._get_api_response(\u001B[33m\"\u001B[39m\u001B[33mget\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    481\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/virtualenvs/earth-systems-homework-assignment-1-gqaom8D6/lib/python3.12/site-packages/ecmwf/datastores/processing.py:459\u001B[39m, in \u001B[36mRemote._wait_on_results\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    457\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.results_ready:\n\u001B[32m    458\u001B[39m     \u001B[38;5;28mself\u001B[39m.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mresults not ready, waiting for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msleep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m seconds\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    460\u001B[39m     sleep = \u001B[38;5;28mmin\u001B[39m(sleep * \u001B[32m1.5\u001B[39m, \u001B[38;5;28mself\u001B[39m.sleep_max)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
